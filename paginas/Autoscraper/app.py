from __future__ import annotations
from dataclasses import dataclass

@dataclass
class AppConfig:
    base_url: str
    out_csv: str
    timeout: int
    retries: int
    fresh_days: int
    user_agent: str

class App:
    def __init__(self, api, translator, repo, merger):
        self.api = api
        self.translator = translator
        self.repo = repo
        self.merger = merger

    def run(self) -> None:
        """
        Ejecuta el proceso con batching:
        - Autocor: lote por pÃ¡gina.
        - PatioTuerca: lote por aÃ±o.
        - Otros: modo monolÃ­tico (compatibilidad).
        """
        if hasattr(self.api, "fetch_year") and hasattr(self.api, "anios"):
            self._run_patiotuerca_by_year()
        elif hasattr(self.api, "discover_first_page") and hasattr(self.api, "fetch_page"):
            self._run_autocor_by_page()
        elif hasattr(self.api, "fetch_all"):
            self._run_monolithic()
        else:
            raise RuntimeError("API no compatible con App.run()")

    # -----------------------
    #  MODO BATCH: PATIOTUERCA
    # -----------------------
    def _run_patiotuerca_by_year(self) -> None:
        """
        PatioTuerca se procesa por lotes de aÃ±o.
        Se guarda el CSV despuÃ©s de cada aÃ±o para no perder progreso.
        """
        print("â–¶ Ejecutando en modo batch por aÃ±o (PatioTuerca)")

        # Cargar CSV existente una sola vez
        merged = self.repo.load()
        total_metrics = {"kept": 0, "updated": 0, "added": 0}

        for anio in self.api.anios:
            print(f"\nðŸ“† Procesando aÃ±o {anio}...")
            entities = self.api.fetch_year(anio)

            if not entities:
                print(f"  (sin resultados para {anio})")
                continue

            incoming_rows = [self.translator.build_csv_row(e) for e in entities]

            merged, metrics = self.merger.merge(merged, incoming_rows)

            # Acumular mÃ©tricas
            for k in ("kept", "updated", "added"):
                total_metrics[k] += metrics.get(k, 0)

            # Guardar despuÃ©s de cada aÃ±o
            self.repo.save(merged)
            print(
                f"  âœ“ AÃ±o {anio}: total_now={metrics['total']} | "
                f"kept={metrics['kept']} | updated={metrics['updated']} | added={metrics['added']}"
            )
            print(f"  âœ“ CSV parcial guardado en: {self.repo.path}")

        total = len(merged)
        print(
            f"\nâœ“ Merge completado (todos los aÃ±os) â†’ Total filas: {total} | "
            f"Conservadas vigentes: {total_metrics['kept']} | "
            f"Actualizadas: {total_metrics['updated']} | "
            f"Nuevas: {total_metrics['added']}"
        )
        print(f"âœ“ CSV final: {self.repo.path}")

    # -----------------------
    #  MODO BATCH: AUTOCOR
    # -----------------------
    def _run_autocor_by_page(self) -> None:
        """
        Procesa Autocor por lotes de pÃ¡gina.
        Guarda el CSV despuÃ©s de cada pÃ¡gina.
        """
        print("â–¶ Ejecutando en modo batch por pÃ¡gina (Autocor)")

        merged = self.repo.load()
        total_metrics = {"kept": 0, "updated": 0, "added": 0}

        # PÃ¡gina 1
        page_count, entities_page1 = self.api.discover_first_page()
        print(f"  ðŸ“„ Total de pÃ¡ginas reportadas: {page_count}")

        # Procesar pÃ¡gina 1
        pages = [(1, entities_page1)]

        # PÃ¡ginas 2...N
        for p in range(2, page_count + 1):
            pages.append((p, self.api.fetch_page(p)))

        # Procesar lote por lote
        for page_num, page_entities in pages:
            print(f"\nðŸ“„ Procesando pÃ¡gina {page_num}/{page_count}...")

            if not page_entities:
                print("  (pÃ¡gina vacÃ­a)")
                continue

            incoming_rows = [self.translator.build_csv_row(e) for e in page_entities]
            merged, metrics = self.merger.merge(merged, incoming_rows)

            # Acumular mÃ©tricas totales
            for k in ("kept", "updated", "added"):
                total_metrics[k] += metrics.get(k, 0)

            # Guardado por pÃ¡gina
            self.repo.save(merged)
            print(
                f"  âœ“ PÃ¡gina {page_num}: total_now={metrics['total']} | "
                f"kept={metrics['kept']} | updated={metrics['updated']} | added={metrics['added']}"
            )
            print(f"  âœ“ Guardado parcial en: {self.repo.path}")

        total = len(merged)
        print(
            f"\nâœ“ Merge completado (todas las pÃ¡ginas) â†’ Total filas: {total} | "
            f"Conservadas vigentes: {total_metrics['kept']} | "
            f"Actualizadas: {total_metrics['updated']} | "
            f"Nuevas: {total_metrics['added']}"
        )
        print(f"âœ“ CSV final: {self.repo.path}")

    # -----------------------
    #  MODO MONOLÃTICO
    # -----------------------
    def _run_monolithic(self) -> None:
        """Modo original (no batch)."""

        if hasattr(self.api, "fetch_all"):
            entities = self.api.fetch_all()
        else:
            page_count, entities = self.api.discover_first_page()
            for p in range(2, page_count + 1):
                entities.extend(self.api.fetch_page(p))

        incoming_rows = [self.translator.build_csv_row(e) for e in entities]

        existing = self.repo.load()
        merged, metrics = self.merger.merge(existing, incoming_rows)

        self.repo.save(merged)

        print(
            f"âœ“ Merge completado â†’ Total: {metrics['total']} | "
            f"kept={metrics['kept']} | updated={metrics['updated']} | added={metrics['added']}"
        )
        print(f"âœ“ CSV: {self.repo.path}")